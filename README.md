---
title: GenAI PDF Q&A Chatbot (Groq)
emoji: ğŸ“„
colorFrom: indigo
colorTo: purple
sdk: gradio
sdk_version: "4.44.0"
app_file: app.py
pinned: false
---

# GenAI PDF Q&A Chatbot (RAG Â· LangChain Â· FAISS Â· **Groq**)

Upload PDFs â†’ build a vector index â†’ ask grounded questions with page-level citations.  
This Space uses **LangChain**, **FAISS**, and **Groq** LLMs (e.g., `llama-3.1-70b-versatile`).  
If `GROQ_API_KEY` isnâ€™t set, it falls back to OpenAI (if provided) or shows a helpful message.

---

## ğŸš€ Features
- ğŸ“¥ Upload multiple PDFs
- ğŸ”ª Smart chunking (`RecursiveCharacterTextSplitter`)
- ğŸ§  Embeddings:  
  - **OpenAI** `text-embedding-3-small` when `OPENAI_API_KEY` is set  
  - Fallback: **sentence-transformers/all-MiniLM-L6-v2** (CPU-friendly, no key)
- ğŸ—ƒï¸ Vector store: **FAISS** (persisted to `storage/index/`)
- ğŸ’¬ LLM: **Groq** via `langchain_groq` (default), or OpenAI if configured
- ğŸ” Citations: filename + page (e.g., `[source: myfile.pdf p.3]`)

---

## âœ… Quick Start (on this Space)
1. **Add secrets** (Space â†’ *Settings* â†’ *Variables and secrets*):
   - `GROQ_API_KEY` = *your Groq key*  âœ…  
   - *(optional)* `GROQ_MODEL` = `llama-3.1-70b-versatile` (default)  
   - *(optional)* `OPENAI_API_KEY` = *your OpenAI key* (enables OpenAI embeddings; otherwise uses local sentence-transformers)
2. Wait for the Space to rebuild.
3. Open the app:
   - Upload 1+ PDFs
   - Click **ğŸ”§ Build Index**
   - Ask a question with **ğŸ’¬ Ask**

> **Note:** If your PDFs are scans (images), text may not be extractable. Run OCR first.

---

## ğŸ”§ Tech Stack
- **UI**: Gradio Blocks
- **RAG**: LangChain + FAISS
- **Embeddings**: OpenAI or Sentence-Transformers (fallback)
- **LLM**: Groq (`langchain_groq`) â€” default model `llama-3.1-70b-versatile`

---

## ğŸ—‚ï¸ Project Structure
```
app.py                # Gradio UI + RAG pipeline
requirements.txt      # Python deps for Spaces
README.md             # This file (with Spaces front-matter)
storage/              # created at runtime to store FAISS index
```

---

## ğŸ” Secrets (recap)
- `GROQ_API_KEY` **(required for Groq)**
- `GROQ_MODEL` *(optional)* â†’ e.g., `llama-3.1-70b-versatile`, `mixtral-8x7b-32768`, `gemma2-9b-it`
- `OPENAI_API_KEY` *(optional)* â†’ used for OpenAI embeddings or fallback LLM

---

## ğŸ§© How It Works
1. **Load PDFs** with `PyPDFLoader` (keeps `source` & `page` in metadata)
2. **Split** into ~900-char chunks with 150 overlap
3. **Embed** chunks (OpenAI if key; else `all-MiniLM-L6-v2`)
4. **Index** with FAISS â†’ saved to `storage/index/`
5. **Retrieve** top-k chunks for the query (k=4)
6. **Generate** answer with Groq LLM (grounded prompt: â€œIf not in docs, say you donâ€™t knowâ€)
7. **Cite** sources as `[source: filename.pdf p.#]`

---

## ğŸ§ª Local Dev (optional)
```bash
pip install -r requirements.txt
python app.py
# open http://127.0.0.1:7860
```

---

## ğŸ©¹ Troubleshooting
- **Configuration error (this page)** â†’ Make sure the YAML front-matter at the top of this README matches:
  - `sdk: gradio`, `app_file: app.py`, and a valid `sdk_version` (e.g., `"4.44.0"`)
- **Build fails** â†’ Check `requirements.txt` includes:
  ```
  gradio
  langchain
  langchain-community
  langchain-openai
  langchain-groq
  groq
  faiss-cpu
  sentence-transformers
  pypdf
  tiktoken
  numpy
  ```
- **â€œNo LLM provider configuredâ€** â†’ Add `GROQ_API_KEY` in *Variables & secrets*
- **Empty/irrelevant answers** â†’ Ensure you clicked **ğŸ”§ Build Index** after uploading PDFs
- **Scanned PDFs** â†’ Use OCR before uploading

---

## ğŸ“„ License
Choose the license that fits your needs (e.g., MIT).
